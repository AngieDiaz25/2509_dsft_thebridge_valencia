{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregación y agrupación"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una parte esencial del análisis de grandes cantidades de datos es la sumarización eficiente; la capacidad de hacer operaciones tales como ``sum()``, ``mean()``, ``median()``, ``min()``, and ``max()`` dónde un sólo número da visión de la naturaleza de una gran cantidad de datos. En la clase de hoy vamos a explorar las agregaciones que nos ofrece Pandas, desde las más simple, que ya hemos visto y trabajado con los Numpy Arrays, a los más sofisticados basados en el concepto de ``GroupBy``."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo hemos usado en otros capítulos, vamos a usar la función ``display()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class display(object):\n",
    "    \"\"\"Representador HTML de múltiples objetos\"\"\"\n",
    "    template = \"\"\"<div style=\"float: left; padding: 10px;\">\n",
    "    <p style='font-family:\"Courier New\", Courier, monospace'>{0}</p>{1}\n",
    "    </div>\"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        return '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n",
    "                         for a in self.args)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '\\n\\n'.join(a + '\\n' + repr(eval(a))\n",
    "                           for a in self.args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planets Dataset\n",
    "\n",
    "Para explicar las bases, vamos a usar el **Dataset** de Planets, disponible con el paquete de ``Seaborn``, que ya descubriremos en el módulo de visualización. Da información de los planetas que los astrónomos han descubierto orbitando en otras estrellas (conocidos como *planetas extrasolares* o *exoplanetas*). Puede ser descargado con un comando de la librería ``Seaborn``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "planets = sns.load_dataset('planets')\n",
    "planets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vemos como es el data set- info() head() tail() describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has some details on the 1,000+ extrasolar planets discovered up to 2014."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregación básica en Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anteriormente, ya hemos visto algunas de las funciones de agregación que teníamos en Numpy. Con un sólo nivel dimensional, la agregación funciona así para una ``Series``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "ser = pd.Series(rng.rand(5))\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para un ``Dataframe``, la agregación devuelve un resultado **para cada columna**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': rng.rand(5),\n",
    "                   'B': rng.rand(5)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si así lo disponemos con el argumento ``axis``, podemos agregar **en cada fila**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si quiero ver la media por filas \n",
    "df.mean(axis='columns')\n",
    "\n",
    "#df.mean(axis=1) si lo preferimos "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las ``Series`` y ``Dataframe`` de Pandas incluye todos los tipos de agregaciones que hemos visto ya para los Numpy Arrays, pero además, tenemos el método ``describe()`` que computa distintos agregaciones estándar para cada columna para darnos información clave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina todas las filas que contengan valores nulos (NaN)\n",
    "# y luego muestra un resumen estadístico de las columnas\n",
    "planets.dropna().describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es muy útil para comenzar a entender de manera general las propiedades del Dataset. Por ejemplo, sabemos por la columna ``year`` que el primer exoplaneta fue descubierto en 1989, y que la mitad de ellos no habían sido descubiertos antes del año 2009. Esto es gracias a la misión *Kepler*, que es un telescopio espacial que está específicamente para buscar planetas que eclipsan a otras estrellas. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes agregaciones vienen con el paquete de Pandas:\n",
    "\n",
    "| Agregación              | Descripción                     |\n",
    "|--------------------------|---------------------------------|\n",
    "| ``count()``              | Número total de elementos          |\n",
    "| ``first()``, ``last()``  | Primer y último elemento             |\n",
    "| ``mean()``, ``median()`` | Media y mediana                 |\n",
    "| ``min()``, ``max()``     | Mínimo y máximo             |\n",
    "| ``std()``, ``var()``     | Desviación estándar y varianza |\n",
    "| ``mad()``                | Desviación media absoluta         |\n",
    "| ``prod()``               | Producto de todos los elementos            |\n",
    "| ``sum()``                | Suma de todos los elementos               |\n",
    "\n",
    "Todos están presentes como objetos de ``Dataframe`` y ``Series``."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ir más allá de los datos estas agregaciones no son suficiente. El siguiente nivel de sumarización es el conocido ``groupby``, que nos permite procesar subsets de datos de manera rápida y eficiente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy: Split, Apply, Combine\n",
    "\n",
    "Agregaciones más simples nos permiten saborear el dataset, pero casi siempre preferiremos agregar condicionalmente en algún o algunas dimensiones/índices: esto se implementa con la operación ``groupby``.\n",
    "\n",
    "El nombre de *Group By* viene de un comando de **SQL**, pero quizás es más explicativo verlo por el término que describió Hadley Wickham de RStats: *split, apply, combine*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split, apply, combine\n",
    "\n",
    "Un ejemplo muy canónico de este término *split-apply-combine* es el de agregar en forma de suma."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto nos ayuda a aclarar lo que ``groupby`` realiza:\n",
    "\n",
    "- El paso de **split/separar** involucra romper y agrupar el ``Dataframe`` dependiento del valor de una clave especificada.\n",
    "- El paso de **apply/aplicar** involucra computar alguna función, usualmente una agregación, una transformación, un filtrado entre esos grupos individuales.\n",
    "- El paso de **combine/combinar** une esos resultados en un array de salida/output\n",
    "\n",
    "Mientras esto podría ser realizado de manera manual usando una combinación de *masking*, agregación y unión que ya hemos visto antes, existe un pero importante, **que las agregaciones a realizar no tienen porqué ser instanciadas**. En lugar de eso, ``groupby`` puede (casi todas las veces) hacer esto en una sola llamada a los datos, realizando automáticamente el cálculo de la agregación para cada grupo de una sola vez. El poder de ``Groupby`` radica en hacer esos pasos de manera combinada por nosotros: El usuario no necesita pensar en cómo va a hacer la computación.\n",
    "\n",
    "Como ejemplo, vamos a usar Pandas para la computación en base al siguiente diagrama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'department': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'VV': range(6)})\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La versión más simple de *split-apply-combine* puede ser realizado con el método ``groupby()``, pasando el nombre de la key a agregar como argumento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('department')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date cuenta que lo que ha devuelto no es un ``Dataframe``, es un objeto de ``DataFrameGroupBy``. Este objeto en dónde la mágia ocurre, puedes pensar en el cómo una vista especial de un ``Dataframe``, en dónde tiene la instrucción de cómo se van a distribuir los grupos pero no va a realizarse hasta que la agregación sea **aplicada**. Esta evaluación difusa o *\"lazy evaluation\"* significa que agregaciones comunes como las que hemos presentado podrían ser implementadas facilmente y de manera transparente para el usuario.\n",
    "\n",
    "Para producir un resultado, **debemos agregar este objeto**, cosa que nos dará un resultado en base a la agregación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VV'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupa el DataFrame por la columna 'department'\n",
    "# y calcula la media de todas las columnas numéricas en cada grupo\n",
    "df_grouped = df.groupby('department').mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "El método de ``sum()`` es solo una de las posibilidades aquí, podemos aplicar culqueir tipo de función de agregación de Pandas o de Numpy, además, podemos aplicar de manera simultánea cualquier operación al ``Dataframe``. Ahora lo veremos en detalle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El objeto Groupby\n",
    "\n",
    "El objeto ``Groupby`` es una abstracción muy flexible, se podría tratar como una colección de un ``Dataframe``. Vamos a ver a continuación ejemplos con nuestro ``Dataframe`` de Planets:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexado de columnas\n",
    "\n",
    "Ya lo adelantabamos anteriormente, el objeto ``Groupby`` soporta la indexación de la misma manera que el ``Dataframe``, devolviendo una modificación del objeto ``Groupby``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets['method'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.groupby('method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupa el DataFrame 'planets' por la columna 'method'\n",
    "# (el método con el que se descubrió el planeta)\n",
    "# y calcula la media de la columna 'orbital_period' para cada grupo\n",
    "planets.groupby('method')['orbital_period'].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí hemos seleccionado un grupo concreto de tipo Series del DataFrame original haciendo referencia a su nombre de columna.\n",
    "Al igual que con el objeto GroupBy, no se realiza ningún cálculo hasta que llamamos a alguna función de agregación sobre el objeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrae la columna 'method' del DataFrame planets\n",
    "# Obtiene los valores únicos en esa columna con .unique()\n",
    "# Cuenta cuántos métodos distintos hay con len()\n",
    "\n",
    "len(planets['method'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.groupby('method')[['orbital_period']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# media del período orbital de los planetas descubiertos por Astrometry (codigo explicado en la siguiente celda)\n",
    "planets[planets['method']=='Astrometry'][['orbital_period']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El codigo anterior paso a paso \n",
    "\n",
    "# Filtra el DataFrame para quedarte solo con las filas donde\n",
    "# la columna 'method' sea exactamente 'Astrometry'\n",
    "planets[planets['method'] == 'Astrometry']\n",
    "\n",
    "# De ese subconjunto selecciona la columna 'orbital_period'\n",
    "planets[planets['method'] == 'Astrometry'][['orbital_period']]\n",
    "\n",
    "# Calcula la media de los períodos orbitales en ese subconjunto\n",
    "planets[planets['method'] == 'Astrometry'][['orbital_period']].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos hacemos una idea de la escala general de los periodos orbitales en días que cada método de observación es capaz de abarcar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteración entre grupos\n",
    "\n",
    "El objeto ``Groupby`` soporta la iteración directa entre grupos, devolviendo cada grupo como una ``Series`` o un ``Dataframe``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Recorremos el DataFrame agrupado por la columna 'method'\n",
    "# .groupby('method') agrupa las filas que tienen el mismo valor en esa columna.\n",
    "# Cada grupo será un subconjunto del DataFrame original.\n",
    "for (method, group) in planets.groupby('method'):\n",
    "    \n",
    "    # En cada iteración:\n",
    "    #  - 'method' → es el nombre del grupo (por ejemplo: 'Transit', 'Radial Velocity', etc.)\n",
    "    #  - 'group' → es un nuevo DataFrame que contiene solo las filas de ese método\n",
    "    \n",
    "    # .shape devuelve una tupla (filas, columnas)\n",
    "    # En este contexto indica cuántas observaciones hay en ese grupo\n",
    "    # y cuántas columnas tiene (por ejemplo: (397, 6) → 397 filas, 6 columnas)\n",
    "    \n",
    "    # .format() se usa para imprimir texto con formato.\n",
    "    # {0:30s} → reserva 30 caracteres para el primer valor (cadena) alineado a la izquierda.\n",
    "    # {1} → inserta el segundo valor (aquí la tupla del tamaño del grupo)\n",
    "    \n",
    "    print(\"{0:30s} shape={1}\".format(method, group.shape))\n",
    "\n",
    "# ============================================\n",
    "# EJEMPLO DE SALIDA:\n",
    "# Astrometry                     shape=(2, 6)\n",
    "# Eclipse Timing Variations      shape=(9, 6)\n",
    "# Imaging                        shape=(38, 6)\n",
    "# Microlensing                   shape=(23, 6)\n",
    "# Orbital Brightness Modulation  shape=(3, 6)\n",
    "# Pulsar Timing                  shape=(5, 6)\n",
    "# Pulsation Timing Variations    shape=(1, 6)\n",
    "# Radial Velocity                shape=(553, 6)\n",
    "# Transit                        shape=(397, 6)\n",
    "# Transit Timing Variations      shape=(4, 6)\n",
    "# ============================================\n",
    "\n",
    "# INTERPRETACIÓN:\n",
    "# Cada línea muestra un método de descubrimiento de planetas\n",
    "# (columna 'method') y cuántas veces aparece en el DataFrame.\n",
    "# Ejemplo:\n",
    "#   - 'Radial Velocity' tiene 553 registros (553 planetas detectados por ese método)\n",
    "#   - 'Transit' tiene 397 registros\n",
    "#   - 'Astrometry' solo tiene 2 registros\n",
    "\n",
    "# ============================================\n",
    "# OPCIONAL (versión alternativa más compacta):\n",
    "# Si solo quieres ver el conteo de filas por grupo sin recorrer con for:\n",
    "# planets.groupby('method').size()\n",
    "# Esto devuelve una Serie con el número de filas por método.\n",
    "# ============================================\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto puede ser útil para hacer ciertas operaciones de manera más manual, aunque es más rápido usar la funcionalidad de ``apply``, que veremos a continuación."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métodos de envío\n",
    "\n",
    "A través de la magia de las clases de Python, cualquier método no implementado explícitamente por el objeto ``GroupBy`` será pasado y llamado en los grupos, ya sean objetos ``DataFrame`` o ``Series``.\n",
    "Por ejemplo, puedes utilizar el método ``describe()`` de ``DataFrame`` para realizar un conjunto de agregaciones que describan cada grupo en los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrupa por 'method' y genera estadísticas descriptivas de la columna 'year'\n",
    "temp = planets.groupby('method')['year'].describe()  \n",
    "temp  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mirar esta tabla nos ayuda a entender mejor los datos: por ejemplo, la gran mayoría de los planetas se han descubierto por los métodos de *Radial Velocity* y *Transit*, aunque este último sólo se hizo común (debido a los nuevos y más precisos telescopios) en la última década.\n",
    "Los métodos más recientes parecen ser el de la *Transit Timing Variations* y el de la *Orbital Brightness Modulation*, que no se utilizaron para descubrir un nuevo planeta hasta 2011.\n",
    "\n",
    "Este es sólo un ejemplo de la utilidad de los métodos de envío. Fíjate en que se aplican *a cada grupo individual*, y los resultados se combinan dentro de ``GroupBy`` y se devuelven. De nuevo, cualquier método válido de ``DataFrame`` o ``Series`` puede utilizarse en el objeto ``GroupBy`` correspondiente, ¡lo que permite realizar operaciones muy flexibles y potentes!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate, filter, transform y apply\n",
    "\n",
    "Antes nos hemos centrado en la agregación para la operación de combinación, pero hay más opciones disponibles. En particular, los objetos ``GroupBy`` tienen los métodos ``agregate()``, ``filter()``, ``transform()``, y ``apply()`` que implementan eficientemente una variedad de operaciones útiles antes de combinar los datos agrupados.\n",
    "\n",
    "En las siguientes subsecciones, utilizaremos este ``DataFrame``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "df = pd.DataFrame({'department': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'anio': [2020,2020,2020,2021,2021,2021],\n",
    "                   'VV': rng.randint(0, 10, 6)},\n",
    "                   columns = ['department', 'anio', 'VV'])\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agregación\n",
    "\n",
    "Ya estamos familiarizados con las agregaciones ``GroupBy`` con ``sum()``, ``median()``, y similares, pero el método ``aggregate()`` permite una flexibilidad aún mayor.\n",
    "Puede tomar una cadena, una función, o una lista de ellas, y calcular todos los agregados a la vez.\n",
    "\n",
    "Aquí hay un ejemplo rápido que combina todo esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('department').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar el DataFrame por la columna 'department'\n",
    "# .aggregate() permite aplicar una o varias funciones de agregación a cada grupo\n",
    "# En este caso: calcula el mínimo (min), la mediana (np.median) y el máximo (max) por grupo\n",
    "df_grouped = df.groupby('department').aggregate(['min', np.median, max])\n",
    "\n",
    "df_grouped"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro patrón útil es pasar un diccionario que asigna los nombres de las columnas a las operaciones que deben aplicarse a esa columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar el DataFrame por la columna 'department'\n",
    "# Usamos .aggregate() con un diccionario para aplicar funciones específicas a columnas concretas:\n",
    "#   - En la columna 'anio' se calcula el valor mínimo\n",
    "#   - En la columna 'VV' se calcula el valor medio (promedio) \n",
    "\n",
    "df_grouped = df.groupby('department').aggregate({'anio': 'min',\n",
    "                                                'VV': 'mean'}).rename(columns={'anio':'anio_min', # Renombramos la columna resultante 'anio' -> 'anio_min'\n",
    "                                                                                \"VV\":\"VV_mean\"}) # Renombramos la columna resultante 'VV' -> 'VV_mean' \n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar el DataFrame por las columnas 'anio' y 'department'\n",
    "# Para cada combinación (anio, department) calcula la media de todas las columnas numéricas\n",
    "# A diferencia del caso anterior, aquí no se resume todo el departamento en una fila,\n",
    "# sino que se obtiene el detalle año por año para cada departamento\n",
    "# (si se quisiera que 'anio' y 'department' no fueran índice, se podría usar as_index=False)\n",
    "df_grouped = df.groupby([\"anio\", \"department\"]).mean() \n",
    "\n",
    "df_grouped"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrado\n",
    "\n",
    "Una operación de filtrado permite descartar datos en función de las propiedades del grupo.\n",
    "Por ejemplo, podríamos querer mantener todos los grupos en los que la desviación estándar es mayor que algún valor crítico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una funcion de filtrado que usaremos luego\n",
    "    \n",
    "def filter_func(x):\n",
    "    return x['VV'].min() > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recordamos la sintaxis mascara boleana \n",
    "\n",
    "df['VV'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recordamos la sintaxis mascara boleana aplicada\n",
    "\n",
    "df[df['VV'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿La función display del principio del notebook sirve para esto?\n",
    "# Sí. Asegúrate de importarla desde IPython.display.\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Mostrar el DataFrame original 'df'\n",
    "# Luego el resultado de agrupar por 'department' y calcular el mínimo de cada grupo\n",
    "# Finalmente el DataFrame filtrado con filter_func (min(VV) > 1)\n",
    "\n",
    "min_by_dept = df.groupby('department').min()\n",
    "filtered = df.groupby('department').filter(filter_func)\n",
    "\n",
    "display(Markdown(\"**DataFrame original (`df`)**\"))\n",
    "display(df)\n",
    "\n",
    "display(Markdown(\"**Mínimos por `department`**\"))\n",
    "display(min_by_dept)\n",
    "\n",
    "display(Markdown(\"**Filtrado con `filter_func` (min(VV) > 1)**\"))\n",
    "display(filtered)\n",
    "\n",
    "# Si prefieres todo en una sola llamada (sin títulos), también funciona:\n",
    "# display(df, min_by_dept, filtered)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de filtrado debe devolver un valor booleano que especifica si el grupo pasa el filtrado. No pasa el grupo B al no superar uno de sus registros el hecho de ser superior de cero."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación\n",
    "\n",
    "Mientras que la agregación debe devolver una versión reducida de los datos, la transformación puede devolver alguna versión transformada de los datos completos para recombinar.\n",
    "Para tal transformación, la salida tiene la misma forma que la entrada.\n",
    "Un ejemplo común es centrar los datos restando la media del grupo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferencia entre .aggregate() y .transform():\n",
    "# - .aggregate() (o .agg()) devuelve un resultado reducido (por ejemplo: min, max, mean), \n",
    "#   es decir, colapsa el grupo en un único valor por función.\n",
    "# - .transform(), en cambio, devuelve un resultado del mismo tamaño que el grupo original.\n",
    "#   Esto permite \"transformar\" cada valor y luego recombinar en un DataFrame de la misma forma que el original.\n",
    "\n",
    "# Ejemplo común de transformación: centrar los datos de cada grupo restando la media del grupo\n",
    "# La salida tiene la MISMA forma que la entrada, pero transformada.\n",
    "\n",
    "# Definimos una función personalizada que normaliza: resta la media y divide por la desviación estándar del grupo\n",
    "def mi_funcion(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "# Aplicamos la función a cada grupo con transform: normalización dentro de cada 'department'\n",
    "df_normalizado = df.groupby('department').transform(mi_funcion)\n",
    "\n",
    "# Otro ejemplo: solo centrar (restar la media del grupo)\n",
    "df_centrado = df.groupby('department').transform(lambda x: x - x.mean())\n",
    "\n",
    "# Mostrar resultados\n",
    "display(\n",
    "    df.head(),             # Datos originales (primeras filas)\n",
    "    df_normalizado.head(), # Datos normalizados (media=0, std=1 dentro de cada departamento) \n",
    "    df_centrado.head()     # Datos centrados (media=0 dentro de cada departamento)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Anexo explicacion resultados](Anexo_transformacion.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Mini bonus \n",
    "[Que es Lambda](https://ellibrodepython.com/lambda-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El método apply()\n",
    "\n",
    "El método ``apply()`` permite aplicar una función arbitraria a los resultados del grupo.\n",
    "La función debe procesar un ``DataFrame``, y devolver un objeto Pandas (por ejemplo, ``DataFrame``, ``Series``) o un escalar; la operación de combinación se adaptará al tipo de resultado devuelto.\n",
    "\n",
    "Por ejemplo, aquí hay un ``apply()`` que normaliza la primera columna por la suma de la segunda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abro aply para visualizar (no hacerle mucho caso)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class display(object):\n",
    "    \"\"\"Representador HTML de múltiples objetos\"\"\"\n",
    "    template = \"\"\"<div style=\"float: left; padding: 10px;\">\n",
    "    <p style='font-family:\"Courier New\", Courier, monospace'>{0}</p>{1}\n",
    "    </div>\"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        return '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n",
    "                         for a in self.args)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '\\n\\n'.join(a + '\\n' + repr(eval(a))\n",
    "                           for a in self.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función personalizada que recibe un grupo (sub-DataFrame)\n",
    "def norm_by_data2(x):\n",
    "    # Dentro de cada grupo, dividimos la columna 'anio'\n",
    "    # entre la suma de la columna 'VV' del mismo grupo\n",
    "    # Esto normaliza los valores de 'anio' usando la \"escala\" de 'VV'\n",
    "    x['anio'] /= x['VV'].sum()\n",
    "    return x  # devolvemos el grupo transformado\n",
    "\n",
    "# Mostrar el DataFrame original y luego el resultado de aplicar la función por grupo\n",
    "# 'department' define los grupos\n",
    "display('df', \"df.groupby('department').apply(norm_by_data2)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``apply()`` dentro de un ``GroupBy`` es bastante flexible: el único criterio es que la función toma un ``DataFrame`` y devuelve un objeto Pandas o un escalar; ¡lo que hagas en medio depende de ti!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Especificar una key de separación\n",
    "\n",
    "En los ejemplos simples presentados anteriormente, agrupamos el ``DataFrame`` en un solo nombre de columna.\n",
    "Esta es sólo una de las muchas opciones por las que los grupos pueden ser definidos, y vamos a ir a través de algunas otras opciones para la especificación de los grupos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Una lista, array, series, o index dando los grupos de antemano\n",
    "\n",
    "La clave puede ser cualquier serie o lista cuya longitud coincida con la del ``DataFrame``. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una lista L con etiquetas numéricas que servirá para agrupar las filas\n",
    "L = [0, 1, 0, 1, 2, 0]\n",
    "\n",
    "# Usamos groupby(L) para agrupar el DataFrame 'df' siguiendo las etiquetas de la lista\n",
    "# Luego aplicamos .sum() para sumar las columnas numéricas dentro de cada grupo\n",
    "# Finalmente, mostramos el DataFrame original y el resultado agrupado\n",
    "display('df', 'df.groupby(L).sum()')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por supuesto, esto significa que hay otra forma más explicita de realizar el ``df.groupby('key')`` de antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('df', \"df.groupby(df['department']).sum()\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Un índice mapeado de un diccionario o una serie a un grupo\n",
    "\n",
    "Otro método es proporcionar un diccionario que asigne los valores del índice a las claves del grupo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar el índice del DataFrame 'df' a la columna 'department'\n",
    "df2 = df.set_index('department')\n",
    "\n",
    "# Creamos un diccionario de mapeo: cada clave es un valor del índice 'department'\n",
    "# y cada valor indica a qué grupo queremos asignar ese departamento\n",
    "mapping = {'A': 'vowel', 'B': 'consonant', 'C': 'consonant'}\n",
    "\n",
    "# Agrupar 'df2' según el diccionario de mapeo aplicado al índice\n",
    "# Luego sumar las columnas numéricas dentro de cada grupo ('vowel', 'consonant')\n",
    "# Finalmente, mostrar el DataFrame transformado\n",
    "display('df2', 'df2.groupby(mapping).sum()')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cualquier función de python\n",
    "\n",
    "Al igual que el *mapping*, puedes pasar cualquier función de Python que introduzca el valor del índice y del grupo resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el DataFrame 'df2'\n",
    "# Luego agrupar usando groupby(str.lower):\n",
    "#   - str.lower se aplica sobre el índice de 'df2' (que en este caso son los departamentos)\n",
    "#   - Convierte cada etiqueta del índice a minúsculas\n",
    "#   - Así, si hubiera diferencias de mayúsculas/minúsculas ('A' y 'a'), se agrupan juntas\n",
    "# Después calculamos la media de cada grupo con .mean()\n",
    "display('df2', 'df2.groupby(str.lower).mean()')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Una lista de *keys* válidas\n",
    "\n",
    "Además, cualquiera de las opciones de clave anteriores puede combinarse para agruparse en un índice múltiple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar el DataFrame df2 usando una lista de funciones/estructuras:\n",
    "# 1. str.lower → se aplica sobre el índice (department), convirtiéndolo a minúsculas\n",
    "# 2. mapping   → es un diccionario que asigna cada departamento a una categoría ('vowel' o 'consonant')\n",
    "#\n",
    "# El resultado es un groupby con un índice jerárquico (MultiIndex):\n",
    "#   - Primer nivel: el nombre del departamento en minúsculas\n",
    "#   - Segundo nivel: la categoría asignada según el diccionario mapping\n",
    "#\n",
    "# Finalmente se calcula la media de cada grupo con .mean()\n",
    "\n",
    "df2.groupby([str.lower, mapping]).mean()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de *Grouping*\n",
    "\n",
    "Como ejemplo de esto, en un par de líneas de código Python podemos juntar todo y contar los planetas descubiertos por método y por década:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decade = 10 * (planets['year'] // 10)\n",
    "decade = decade.astype(str) + 's'\n",
    "decade.name = 'decade'\n",
    "planets.groupby(['method', decade])['number'].sum().unstack().fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto demuestra el poder de la combinación de muchas de las operaciones que hemos visto hasta ahora cuando se observan conjuntos de datos más realistas.\n",
    "Inmediatamente obtenemos una idea general de cuándo y cómo se han descubierto planetas en las últimas décadas.\n",
    "\n",
    "Aquí sugeriría que profundicéis en estas pocas líneas de código, y evaluaseis los pasos individuales para aseguraros de que entendéis exactamente lo que están haciendo al resultado.\n",
    "Es cierto que es ejemplo algo complicado, pero la comprensión de estas pequeñas píldoras os darán los medios para explorar de manera similar tus propios datos. :-)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot Tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos visto cómo la abstracción ``GroupBy`` nos permite explorar las relaciones dentro de un conjunto de datos.\n",
    "Una *tabla pivotante* es una operación similar que suele verse en las hojas de cálculo y otros programas que operan con datos tabulares.\n",
    "La tabla pivotante o *pivot table* toma como entrada datos simples en forma de columnas y agrupa las entradas en una tabla bidimensional que proporciona un resumen multidimensional de los datos.\n",
    "La diferencia entre las *pivot tables* y ``GroupBy`` a veces puede causar confusión; **ayuda bastante pensar en las *pivot tables* como una versión *multidimensional* de la agregación ``GroupBy``.**\n",
    "Es decir, divides-aplicas-combinas, pero tanto la división como la combinación no se producen en un índice unidimensional, **sino en una cuadrícula bidimensional.**\n",
    "\n",
    "\n",
    "*Las tablas dinámicas en Excel (pivot tables) son herramientas para resumir y analizar grandes cantidades de datos de forma dinámica, permitiendo agrupar, filtrar y calcular valores rápidamente para identificar patrones y tendencias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivación de las Pivot Tables\n",
    "\n",
    "Para los ejemplos de esta sección, utilizaremos la base de datos de pasajeros del *Titanic*, disponible a través de la biblioteca **Seaborn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "titanic = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contiene una gran cantidad de información sobre cada uno de los pasajeros de ese viaje algo maldito, incluyendo el género, la edad, la clase, la tarifa pagada y mucho más."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Tables *a mano*\n",
    "\n",
    "Para empezar a aprender más sobre estos datos, podríamos empezar por agrupar según el género, el estado de supervivencia o alguna combinación de ellos.\n",
    "Como hemos comentado anteriormente, podrías verte tentado a aplicar una operación ``GroupBy``; por ejemplo, veamos la tasa de supervivencia por género:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby('sex')[['survived']].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto nos da inmediatamente una idea: en general, tres de cada cuatro mujeres a bordo sobrevivieron, mientras que sólo uno de cada cinco hombres lo hizo.\n",
    "\n",
    "Esto es útil, pero podríamos ir un paso más allá y analizar la supervivencia por sexo y, por ejemplo, por clase. Utilizando el vocabulario de ``GroupBy``, podríamos proceder de la siguiente manera; agrupamos por clase y sexo, seleccionamos la supervivencia, aplicamos una media agregada, luego combinamos los grupos resultantes, y terminamos descomponemos el índice jerárquico para revelar la multidimensionalidad oculta. En código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto nos da una mejor idea de cómo el género y la clase afectan a la supervivencia, pero el código empieza a parecer un poco confuso.\n",
    "Aunque cada paso de esta cadena tiene sentido a la luz de las herramientas que hemos discutido previamente, la larga cadena de código no es particularmente fácil de leer o utilizar.\n",
    "Este ``GroupBy`` bidimensional es lo suficientemente común como para que Pandas incluya una ruta más sencilla, ``pivot_table``, que maneja precisamente este tipo de agregación multidimensional."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sintaxis de las Pivot Table\n",
    "\n",
    "Aquí está el equivalente a la operación anterior utilizando el método ``pivot_table`` de ``DataFrame``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una tabla dinámica (pivot table) a partir del DataFrame 'titanic'\n",
    "# 'survived' → es la columna cuyos valores queremos resumir\n",
    "# index='sex' → las filas estarán definidas por el sexo (male, female)\n",
    "# columns='class' → las columnas estarán definidas por la clase (First, Second, Third)\n",
    "# aggfunc='mean' → calculamos la media de 'survived' para cada combinación\n",
    "#   (como 'survived' es 0 o 1, la media representa la tasa de supervivencia)\n",
    "titanic.pivot_table('survived', index='sex', columns='class', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usamos .T para transponer\n",
    "titanic.pivot_table('survived', index='class', columns='sex', aggfunc='mean')\n",
    "\n",
    "#titanic.pivot_table('survived', index='class', columns='sex', aggfunc='mean').T\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es mucho más fácil de leer que el enfoque \"por grupos\", y produce el mismo resultado. Como cabría esperar de un crucero transatlántico de principios del siglo XX, el grado de supervivencia favorece tanto a las mujeres como a las clases superiores. Las mujeres de primera clase sobrevivieron con casi total seguridad (¡hola, Rose!), mientras que sólo uno de cada diez hombres de tercera clase sobrevivió (¡lo siento, Jack!)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot tables multi nivel\n",
    "\n",
    "Al igual que en el ``GroupBy``, la agrupación en las tablas dinámicas puede especificarse con múltiples niveles, y a través de una serie de opciones.\n",
    "Por ejemplo, podríamos estar interesados en ver la edad como una tercera dimensión.\n",
    "Agruparemos la edad utilizando la función ``pd.cut``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide la columna \"age\" del DataFrame titanic en intervalos definidos\n",
    "pd.cut(titanic['age'], [0, 18, 80])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasifica las edades en dos grupos (0-18 → 'menores', 18-80 → 'mayores')\n",
    "age = pd.cut(titanic['age'], [0, 18, 80], labels=['menores','mayores'])\n",
    "\n",
    "# Crea una tabla dinámica: filas = sexo+grupo de edad, columnas = clase, valores = conteo de 'survived'\n",
    "titanic.pivot_table('survived', index=['sex', age], columns='class', aggfunc='count')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos aplicar la misma estrategia al trabajar con las columnas; vamos a añadir información sobre la tarifa pagada utilizando ``pd.qcut`` para calcular automáticamente los cuantiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide la columna 'fare' (tarifa) en 2 grupos de igual tamaño usando cuantiles\n",
    "fare = pd.qcut(titanic['fare'], 2)\n",
    "\n",
    "# Tabla dinámica: filas = sexo + grupo de edad, columnas = grupo de tarifa + clase, valores = conteo de 'survived'\n",
    "titanic.pivot_table('survived', ['sex', age], [fare, 'class'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es una agregación cuatridimensional con índices jerárquicos cosa que vimos en Pandas 2, mostrada en una cuadrícula que demuestra la relación entre los valores."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opciones de Pivot table adicionales:\n",
    "\n",
    "La notación completa del método ``pivot_table`` de ``DataFrame`` es la siguiente:\n",
    "\n",
    "```python\n",
    "# Para Pandas 0.18\n",
    "DataFrame.pivot_table(data, values=None, index=None, columns=None,\n",
    "                      aggfunc='mean', fill_value=None, margins=False,\n",
    "                      dropna=True, margins_name='All')\n",
    "```\n",
    "\n",
    "Ya hemos visto ejemplos de los tres primeros argumentos; aquí echaremos un vistazo rápido a los restantes.\n",
    "Dos de las opciones, ``fill_value`` y ``dropna``, tienen que ver con los datos que faltan y son bastante sencillas; no mostraremos ejemplos de ellas aquí.\n",
    "\n",
    "La palabra clave ``aggfunc`` controla qué tipo de agregación se aplica, que es una media por defecto.\n",
    "Al igual que en ``GroupBy``, la especificación de la agregación puede ser una cadena que represente una de las opciones más comunes (por ejemplo, ``sum``, ``mean``, ``count``, ``min``, ``max``, etc.) o una función que implemente una agregación (por ejemplo, ``np.sum()``, ``min()``, ``sum()``, etc.).\n",
    "Además, puede especificarse como un diccionario que asigna una columna a cualquiera de las opciones deseadas anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla dinámica: filas = sexo, columnas = clase; y con aggfunc= muestra suma de sobrevivientes y tarifa media\n",
    "titanic.pivot_table(index='sex', columns='class', aggfunc={'survived':sum, 'fare':'mean'})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fíjate también en que hemos omitido la palabra clave ``values``; al especificar una asignación para ``aggfunc``, ésta se determina automáticamente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A veces es útil calcular los totales a lo largo de cada agrupación.\n",
    "Esto puede hacerse mediante la palabra clave ``margins``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla dinámica: filas = sexo, columnas = clase; calcula promedio de 'survived' y añade totales (margins=True)\n",
    "titanic.pivot_table('survived', index='sex', columns='class', margins=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí esto nos da automáticamente información sobre la tasa de supervivencia por género, la tasa de supervivencia por género y la tasa de supervivencia global del 38%, todo ello por cada categoría de clase.\n",
    "La etiqueta de los márgenes puede especificarse con la palabra clave ``margins_name``, que por defecto es ``\"All\"``."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo: Datos de nacimiento\n",
    "\n",
    "Como ejemplo más interesante, veamos los datos de libre acceso sobre los nacimientos en Estados Unidos, proporcionados por los Centros de Control de Enfermedades (CDC).\n",
    "Estos datos pueden encontrarse en https://raw.githubusercontent.com/jakevdp/data-CDCbirths/master/births.csv\n",
    "(este conjunto de datos ha sido analizado ampliamente por Andrew Gelman y su grupo; míra, por ejemplo, [esta entrada de blog](http://andrewgelman.com/2012/06/14/cool-ass-signal-processing-using-gaussian-processes/)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://raw.githubusercontent.com/jakevdp/data-CDCbirths/master/births.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "births = pd.read_csv('data/births.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si echamos un vistazo a los datos, vemos que son relativamente sencillos: contienen el número de nacimientos agrupados por fecha y sexo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "births.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos empezar a entender estos datos un poco más utilizando una tabla dinámica.\n",
    "Añadamos una columna de década y veamos los nacimientos de hombres y mujeres en función de la década:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "births['decade'] = 10 * (births['year'] // 10)\n",
    "births.pivot_table('births', index='decade', columns='gender', aggfunc='sum')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos inmediatamente que los nacimientos masculinos superan a los femeninos en cada década.\n",
    "Para ver esta tendencia un poco más claramente, podemos utilizar las herramientas de trazado incorporadas en Pandas para visualizar el número total de nacimientos por año:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()  # use Seaborn styles\n",
    "births.pivot_table('births', index='year', columns='gender', aggfunc='sum').plot()\n",
    "plt.ylabel('total births per year');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con una simple tabla dinámica y el método ``plot()``, podemos ver inmediatamente la tendencia anual de los nacimientos por género. A ojo, parece que en los últimos 50 años los nacimientos masculinos han superado a los femeninos en aproximadamente un 5%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
